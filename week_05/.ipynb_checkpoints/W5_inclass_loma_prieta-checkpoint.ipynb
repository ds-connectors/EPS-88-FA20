{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loma Prieta Earthquake, Earthquake Occurrence Statistics: Omori's Law \n",
    "\n",
    "**Last week we:**\n",
    "- pandas DataFrames, indexing, and data cleaning.\n",
    "- Load marine geophysical data (bathymetry and marine magnetic anomalies) from two oceanic ridges.\n",
    "- Select data and drop rows with NaNs.\n",
    "- Plot bathymetry data and evaluate spreading rate.\n",
    "- Declare a function to detrend and filter magnetic anomalie data.\n",
    "- Plot marine magnetic anomaly data and compare spreading rates.\n",
    "\n",
    "**Our goals for today:**\n",
    "- Load a Bay Area seismic catalog of January 01,1989 to December 31, 1995.\n",
    "- Compute the distance and time interval between Loma Prieta quake and subsequant earthquakes to indentify aftershocks.\n",
    "- Filter the aftershocks from the catalog and looked at their distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Run this cell as it is to setup your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On October 17 at 5:15pm PDT (October 18 1989 at 04:15am UTC) the M6.9 Loma Prieta earthquake occurred in the Santa Cruz mountains approximately 80 km southwest of the Berkeley Campus. We will use this earthquake sequence to investigate the performance of catalog declustering algorithm.\n",
    "\n",
    "https://en.wikipedia.org/wiki/1989_Loma_Prieta_earthquake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Earthquake Catalog\n",
    "\n",
    "Load the .csv data file of all the earthquakes from January 01,1989 to December 31, 1995 in the ANSS (Advanced National Seismic System) catalog from between latitudes 36.0-38.5° and longitude -123.0 to -121.0° ([http://ncedc.org/anss/catalog-search.html](http://ncedc.org/anss/catalog-search.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "LP_catalog=pd.read_csv('data/bay_area_anss_1989_1995.csv')\n",
    "LP_catalog['DateTime'] = pd.xxx\n",
    "LP_catalog.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DateTime objects are great!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LP_catalog['DateTime'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LP_catalog.iloc[2]['DateTime'].year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  create data arrays, it will speed up our loops later\n",
    "year=\n",
    "month=\n",
    "day=\n",
    "lat=\n",
    "lon=\n",
    "mag=\n",
    "#number of events \n",
    "nevt=len(year)\n",
    "print(nevt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map the Raw Earthquake Catalog\n",
    "\n",
    "On a map of the Bay Area plot the location of events in the raw catalog. Scale the marker color and size by magnitude.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a Map of the earthquake catalog\n",
    "\n",
    "# Set Corners of Map\n",
    "lat0=\n",
    "lat1=\n",
    "lon0=\n",
    "lon1=\n",
    "tickstep=0.5 #for axes\n",
    "latticks=np.arange(lat0,lat1+tickstep,tickstep)\n",
    "lonticks=np.arange(lon0,lon1+tickstep,tickstep)\n",
    "\n",
    "# coordinates for UC Berkeley\n",
    "Berk_lat = 37.8716\n",
    "Berk_lon = -122.2727\n",
    "\n",
    "plt.figure(1,(10,10))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.set_extent([lon0, lon1, lat0, lat1], crs=ccrs.PlateCarree())\n",
    "ax.coastlines(resolution='10m',linewidth=1)\n",
    "ax.set_xticks(lonticks)\n",
    "ax.set_yticks(latticks, crs=ccrs.PlateCarree())\n",
    "ax.set(xlabel='Longitude', ylabel='Latitude',title='Raw Catalog')\n",
    "\n",
    "# Sort by magnitude to plot largest events on top\n",
    "LP_catalog_sorted = ...\n",
    "#exponent to scale marker size\n",
    "z=...\n",
    "\n",
    "plt.scatter(..., ..., s=..., \n",
    "            c=..., cmap='plasma',alpha=0.4,marker='o') # plot circles on EQs\n",
    "plt.plot(Berk_lon,Berk_lat,'s',color='limegreen',markersize=8)  # plot green square on Berkeley Campus\n",
    "plt.colorbar(label='Magnitude')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Magnitude vs. Time for the Raw Catalog\n",
    "\n",
    "Plot magnitude vs. time for the raw catalog and print out the number of events as we did in-class. Use the `alpha = 0.2` argument in `plot` to make the markers transparent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot magnitude vs. time\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "ax.plot(..., ...,'o',alpha=0.2,markersize=5)\n",
    "locator = mdates.AutoDateLocator()\n",
    "formatter = mdates.ConciseDateFormatter(locator)\n",
    "ax.xaxis.set_major_locator(locator)\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "ax.set(xlabel='Time', ylabel='Magnitude',title='Raw Event Catalog')\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify the aftershocks\n",
    "\n",
    "For each earthquake in the catalog with magnitude M, the subsequent earthquakes are determined to be aftershocks if they occur within a distance ($d$, in km) and time interval ($t$, in days). \n",
    "\n",
    "<img src=\"Figures/aftershock_windows.png\" width=600>\n",
    "\n",
    "To build our algorithm to identify aftershock using these windows we need to convert the year-month-day formate of dates to a timeline in number of days. We'll do this using the function `datetime.date` which for a given year, month, and day returns a datetime class object, which can be used to compute the time interval in days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Determine the index value and number of days from the Loma Prieta Quake\n",
    "\n",
    "Use the pandas dataframe index method `dataframe_name.index` to find where in the catalog the largest quake happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LP_ind = ...\n",
    "LP_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine the number of days from the Loma Prieta\n",
    "days=np.zeros(nevt) # initialize the size of the array days\n",
    "\n",
    "for i in range(0,nevt,1):\n",
    "    d0 = datetime.date(..., ..., ...)\n",
    "    d1 = datetime.date(..., ..., ...)\n",
    "    delta = d1 - d0\n",
    "    days[i]=delta.days # fill days in with the number of days since the first event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to compute the distance between to geographic points on a sphere\n",
    "\n",
    "We also need a function to compute the great circle distance in km between earthquakes. We'll use the haversine formula for the great circle distance which is well conditioned for small distances.\n",
    "\n",
    "<img src=\"Figures/great_circle_eqn.png\" >\n",
    "\n",
    "\n",
    "<img src=\"Figures/Illustration_of_great-circle_distance.svg\" >\n",
    "Great-circle distance shown in red between two points on a sphere, P and Q. \n",
    "Source: https://en.wikipedia.org/wiki/Great-circle_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function computes the spherical earth distance between to geographic points and is used in the\n",
    "#declustering algorithm below\n",
    "def haversine_np(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points\n",
    "    on the earth (specified in decimal degrees)\n",
    "\n",
    "    All args must be of equal length.\n",
    "    \n",
    "    The first pair can be singular and the second an array\n",
    "\n",
    "    \"\"\"\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2]) # convert degrees lat, lon to radians\n",
    "\n",
    "    dlon = ...\n",
    "    dlat = ...\n",
    "\n",
    "    a = ...  # great circle inside sqrt\n",
    "\n",
    "    c = ...   # great circle angular separation\n",
    "    km = ...   # great circle distance in km, earth radius = 6371.0 km\n",
    "    return km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An approximation of the windows sizes according to Gardner and Knopoff (1974) is shown in the equation below. Using this approximation makes programming a windowing algorithm easier. \n",
    "\n",
    "<img src=\"Figures/window_approx.png\" >\n",
    "\n",
    "Use `np.power(base, exponent)` to compute the distance and time interval bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dtest=...   # distance bounds\n",
    "\n",
    "if mag[i] >= ...:\n",
    "    Ttest=...  # aftershock time bounds for M >= 6.5\n",
    "else:\n",
    "    Ttest=...  # aftershock time bounds for M < 6.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put the pieces together to build a aftershock detection algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decluster the Catalog  Note: This cell may take a few minute to complete\n",
    "cnt=... # initialize a counting variable\n",
    "save=np.zeros((1,1000000),dtype=int) # initialize a counting variable\n",
    "\n",
    "i=...\n",
    "# logical if statements to incorporate definitions of Dtest and Ttest aftershock window bounds\n",
    "Dtest=...   # distance bounds\n",
    "if mag[i] >= ...:\n",
    "    Ttest=...  # aftershock time bounds for M >= 6.5\n",
    "else:\n",
    "    Ttest=...  # aftershock time bounds for M < 6.5\n",
    "\n",
    "a=...    # time interval in days to subsequent earthquakes in catalog\n",
    "m=...   # magnitudes of subsequent earthquakes in catalog\n",
    "b=haversine_np(lon[i],lat[i],lon[...],lat[...]) # distance in km to subsequent EQs in catalog\n",
    "\n",
    "icnt=np.count_nonzero(a <= Ttest)   # counts the number of potential aftershocks, \n",
    "                                    # the number of intervals <= Ttest bound\n",
    "if icnt > 0:  # if there are potential aftershocks\n",
    "    itime=np.array(np.nonzero(a <= Ttest)) + (i+1) # indices of potential aftershocks <= Ttest bound\n",
    "    for j in range(0,icnt,1):   # loops over the aftershocks         \n",
    "        if b[j] <= Dtest and m[j] < mag[i]: # test if the event is inside the distance window \n",
    "                                            # and that the event is smaller than the main EQ\n",
    "            save[0][cnt]=itime[0][j]  # index value of the aftershock\n",
    "            cnt += 1 # increment the counting variable\n",
    "\n",
    "                \n",
    "af_ind=...   # This is an array of indexes that will be used to delete events flagged \n",
    "                                      # as aftershocks    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a set of arrays for the aftershock catalog. Use `af_ind` to select the aftershock events fomr the raw calalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the aftershock events\n",
    "aftershock_df = ...\n",
    "aftershock_days=...  #The aftershocks are selected from the days array \n",
    "aftershock_mag=...    #The aftershocks are selected from the mag array \n",
    "aftershock_lon=...    #The aftershocks are selected from the lon array \n",
    "aftershock_lat=...   #The aftershocks are selected from the lat array \n",
    "n2=len(aftershock_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>**_Concept question:_**</font> How many aftershock events were there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Magnitude vs. Time for the Aftershock Catalog\n",
    "\n",
    "Plot magnitude vs. time for the aftershock events and print out the number of events. Use the `alpha = 0.2` argument in `plot` to make the markers transparent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot DeClustered Catalog\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "ax.plot(mdates.date2num(LP_catalog.iloc[LP_ind]['DateTime']), mag[LP_ind[0]],'o',\n",
    "        color='red',markersize=10,label='Loma Prieta')\n",
    "ax.plot(..., ...,'o',alpha=0.2,markersize=5,label='Aftershocks')\n",
    "\n",
    "locator = mdates.AutoDateLocator()\n",
    "formatter = mdates.ConciseDateFormatter(locator)\n",
    "ax.xaxis.set_major_locator(locator)\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "ax.set(xlabel='Time', ylabel='Magnitude',title='Aftershock Event Catalog')\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a histogram of `aftershock_days`\n",
    "Plot a histogram of the number of aftershocks per 20-day period after the main shock. Use `bins=range(0,920,20)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>**_Discussion question:_**</font> How would you describe the distribution of number of aftershocks with time after the main quake?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map the Aftershock Events\n",
    "\n",
    "On a map of the Bay Area plot the location of events in the aftershock catalog. Again scale the marker color and size by magnitude, set `vmax=6.9` so the colorscale matches our original map. Add the locations of UC Berkeley campus and the Loma Prieta event epicenter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a Map of Aftershock events\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/fault_map.png\" width=700>\n",
    "Map of Bay Area faults. \n",
    "Source: https://pubs.er.usgs.gov/publication/fs20163020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>**_Discussion questions:_**</font>  What faults were active? Were aftershocks only triggered on the same fault as the main quake?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the probabilities of one or more M$\\geq$6.7 quake on these fault in the next 23 years?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn in this notebook\n",
    "\n",
    "Save your completed notebook. Click on __File, Download as, HTML__ to save the notebook as a HTML file. Upload it to the [bCourses assignment page](https://bcourses.berkeley.edu/courses/1498475/assignments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
