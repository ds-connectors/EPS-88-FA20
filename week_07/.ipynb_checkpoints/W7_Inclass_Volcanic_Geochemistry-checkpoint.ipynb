{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B testing Igneous Geochemistry Data\n",
    "\n",
    "### Import scientific python libraries\n",
    "\n",
    "Including the seaborn library that we will be using for the first time today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing distributions of data and comparing populations\n",
    "\n",
    "Today we are going to move to dealing with a different type of data -- igneous geochemistry data. Igneous rocks are those that crystallize from cooling magma. Different magmas have different compositions associated with their origin. During class today, we will focuse on data from lava flows (these are called volcanics rocks).\n",
    "\n",
    "There is a big database of geochemical data from rocks called Earthchem: https://www.earthchem.org\n",
    "\n",
    "### Import a dataframe of igneous geochemistry data\n",
    "\n",
    "Let's deal with a subset of data from Earthchem that contains geochemical data from igneous rocks. In the data folder in a file calles `ign.csv` although it is actually tab-separated. It comes from here: https://github.com/brenhinkeller/StatisticalGeochemistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igneous_data = pd.read_csv('./data/ign.csv',sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at what data are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igneous_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of different geochemical data. Note that the major elements are given as weight percent and the the minor elements are parts per million (ppm).\n",
    "\n",
    "## Filter to look at volcanics\n",
    "\n",
    "Let's make it so that we are only dealing with the data from volcanic rocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volcanic_data = igneous_data[igneous_data[...]==...]\n",
    "volcanic_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the data\n",
    "\n",
    "A type of visualization we have used a fair amount are histograms. Let's plot up how much SiO$_2$ there is in the volcanics rocks that are in the Earthchem database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(...,bins=100)\n",
    "plt.xlabel('SiO$_2$ percentage')\n",
    "plt.ylabel('number of measurements')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that instead of having the y-axis be number of values, we can have it be density using `density=True` (normalized to form a probability density, i.e., the area (or integral) under the histogram will sum to 1). Given that the count itself is rather arbitary, this can be an advantageous way to plot a distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(volcanic_data['SIO2'],bins=100,density=...)\n",
    "plt.xlabel('SiO$_2$ percentage')\n",
    "plt.ylabel('...')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel density estimate\n",
    "\n",
    "One of the ways of representing the distribution of a set of datapoints is known as the 'kernel density estimate'. This is a useful way of showing the distribution of data. It places a 'kernel' (generally a normal distribution) at each data point and then sums them up.  This avoids the awkwardness of needing to chose a bin size associated with histograms, for example.\n",
    "\n",
    "Here is an illustration of how this works.\n",
    "\n",
    "<img src=\"./images/kde.png\" width = 600>\n",
    "[Source: https://commons.wikimedia.org/wiki/File:Comparison_of_1D_histogram_and_KDE.png Wikimedia Creative Commons] \n",
    "\n",
    "There are two choices that are consequential when developing a kernel density estimate: the shape of the \"kernel\" and the bandwidth that sets the width of the kernel. The shape doesn't end up mattering too much, but the bandwidth very much does. There are \"rules of thumb\" for the bandwidth that are implemented as the defaults (and therefore often used), but these can be adjusted and it often isn't clear what the \"right choice\" is.\n",
    "\n",
    "### Developing a kernel density estimate with ```kdeplot```\n",
    "\n",
    "The seaborn function ```kdeplot``` generates a kernal density estimate and then plots it. Note that seaborn provides convenience wrapper functions around other scientific python packages. It is using matplotlib for plotting and it is using statsmodels, scipy and numpy for the statistical methods. It combines these into functions that can quickly get these tasks done. The default is a gaussian kernel and Scott's rule of thumb for the bandwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(volcanic_data['SIO2'],shade=True)\n",
    "plt.xlabel('SiO$_2$ percentage')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sns.distplot` function will plot both a density-normalized histogram and a kernel density estimate curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(volcanic_data['SIO2'])\n",
    "plt.xlabel('SiO$_2$ percentage')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a bivariant histogram/scatter plot\n",
    "\n",
    "If we want to investigate how another aspect of the chemistry of volcanic rocks relates to silica content we can use `sns.joinplot` to make a cross-plot. Here let's look at how iron content (FeO) relates to silica content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(volcanic_data['SIO2'], volcanic_data['FEO'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty hard to see what is going on there. Perhaps it will be better if we change the y limit so that it is tighter on the data and make the symbols have a transparency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(volcanic_data['SIO2'], volcanic_data['FEO'],...)\n",
    "plt.ylim(...)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a bivariant kernel density plot\n",
    "\n",
    "Still pretty hard to see what is going on in the above plot, but it is an improvement. Let's put kernel density estimates to use. Here the same kernel density estimate is used and shown for the univariate data on each axis. However, we now have a bivariate kernel density estimate as well. Taken together we can see that there is a strong relationship between SiO$_2$ levels and FeO levels in volcanic rocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(volcanic_data['SIO2'], volcanic_data['FEO'],kind='kde')\n",
    "plt.ylim(0,20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mafic vs. felsic\n",
    "\n",
    "This illustration provides an overview of the compositional difference between different types of igneous rocks:\n",
    "\n",
    "<img src=\"./images/mafic_felsic.jpg\" width = 600>\n",
    "\n",
    "These compositional differences manifest in different material properties which can be observed at active volcanos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating compositional differences between mafic, intermediate and felsic volcanics (iron)\n",
    "\n",
    "Let's first focus on the difference between the iron contenct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(volcanic_data[volcanic_data['COMPOSITION']=='INTERMEDIATE']['FEO'],bins=100,density=True,label='intermediate volcanics')\n",
    "plt.hist(volcanic_data[volcanic_data['COMPOSITION']=='FELSIC']['FEO'],bins=100,density=True,label='felsic volcanics')\n",
    "plt.hist(volcanic_data[volcanic_data['COMPOSITION']=='MAFIC']['FEO'],bins=100,density=True,label='mafic volcanics')\n",
    "plt.xlim(0,20)\n",
    "plt.xlabel('FeO (%)')\n",
    "plt.ylabel('density')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "sns.kdeplot(volcanic_data[volcanic_data['COMPOSITION']=='INTERMEDIATE']['FEO'],label='intermediate volcanics')\n",
    "sns.kdeplot(volcanic_data[volcanic_data['COMPOSITION']=='FELSIC']['FEO'],label='felsic volcanics')\n",
    "sns.kdeplot(volcanic_data[volcanic_data['COMPOSITION']=='MAFIC']['FEO'],label='mafic volcanics')\n",
    "plt.xlim(0,20)\n",
    "plt.xlabel('FeO (%)')\n",
    "plt.ylabel('density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other way to visualize the distributions\n",
    "\n",
    "### The box plot\n",
    "\n",
    "> A box plot (or box-and-whisker plot) shows the distribution of quantitative\n",
    "data in a way that facilitates comparisons between variables or across\n",
    "levels of a categorical variable. The box shows the quartiles of the\n",
    "dataset while the whiskers extend to show the rest of the distribution,\n",
    "except for points that are determined to be \"outliers\" using a method\n",
    "that is a function of the inter-quartile range. *From seaborn docstring*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "sns.boxplot(x=\"COMPOSITION\", y=\"FEO\", data=volcanic_data, order=['FELSIC','INTERMEDIATE','MAFIC'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Violin plot\n",
    "\n",
    "Perhaps you like box plots, but you are also have a new-found love of probability density estimates. Well you are in luck as the violin plot puts them both together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.violinplot(x=\"COMPOSITION\", y=\"FEO\", data=volcanic_data, order=['FELSIC','INTERMEDIATE','MAFIC'])\n",
    "plt.ylim(0,20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating compositional differences between mafic, intermediate and felsic volcanics (sodium)\n",
    "\n",
    "Looking at the this illustration of composition plot we see that it indicates that there is more iron in mafic rocks (which looks to be the case). It also indicated that there is more sodium in felsic rocks.\n",
    "\n",
    "<img src=\"./images/mafic_felsic.jpg\" width = 600>\n",
    "\n",
    "**Code for you to write**\n",
    "\n",
    " Make the following plots to evaluate this assertion:\n",
    "\n",
    "- jointplot of NA2O vs SI02 for the entire volcanic_data set. make one joint plot that is `kind='kde'` and one that is `kind='hex'`\n",
    "- violin plot of NA2O categorized by composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code for you to write**\n",
    "\n",
    "Once you have made these visualizations, calculate the mean NA2O in felsic, intermediate and mafic volcanics. Assign these values to be `mafic_NA20_mean`, `intermediate_NA20_mean` and `felsic_NA20_mean` and print them.\n",
    "\n",
    "Do these values fit with the schematic illustration of the felsic/mafic diagram? What is consistent and what isn't?\n",
    "\n",
    "*write your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B Testing \n",
    "\n",
    "> In modern data analytics, deciding whether two numerical samples come from the same underlying distribution is called A/B testing. The name refers to the labels of the two samples, A and B. \n",
    "\n",
    "> **The Hypotheses**\n",
    "\n",
    "> We can try to answer this question by a test of hypotheses. The chance model that we will test says that there is no underlying difference in the popuations; the distributions in the samples are different just due to chance.\n",
    "\n",
    "> Formally, this is the null hypothesis. We are going to have to figure out how to simulate a useful statistic under this hypothesis. But as a start, let's just state the two natural hypotheses.\n",
    "\n",
    "*from https://www.inferentialthinking.com/chapters/12/1/AB_Testing.html*\n",
    "\n",
    "In the example in Data 8, students are asked to consider the birth weight of babies when the mother was a smoker and when the mother was a nonsmoker. The two hypotheses and the test statistic were:\n",
    "\n",
    "> **Null hypothesis**: In the population, the distribution of birth weights of babies is the same for mothers who don't smoke as for mothers who do. The difference in the sample is due to chance.\n",
    "\n",
    "> **Alternative hypothesis**: In the population, the babies of the mothers who smoke have a lower birth weight, on average, than the babies of the non-smokers.\n",
    "\n",
    "> **Test Statistic**\n",
    "\n",
    "> The alternative hypothesis compares the average birth weights of the two groups and says that the average for the mothers who smoke is smaller. Therefore it is reasonable for us to use the difference between the two group means as our statistic.\n",
    "\n",
    "> We will do the subtraction in the order \"average weight of the smoking group  − average weight of the non-smoking group\". Small values (that is, large negative values) of this statistic will favor the alternative hypothesis.\n",
    "\n",
    "We can use this same approach in considering the sodium content of the lava samples. where the **Null hypothesis** is that sodium content is the same for rocks of different compositions and in difference in the sample is the result of chance. The **Alternative hypothesis** is that the sodium content of felsic lavas is, on average, higher.\n",
    "\n",
    "## Testing the null hypothesis that there is no difference in the sodium content of **mafic and felsic** lavas\n",
    "\n",
    "To start with, let's consider the difference between mafic and felsic lavas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volcanic_felsic_mafic = volcanic_data[...]\n",
    "volcanic_felsic_mafic = pd.DataFrame(volcanic_felsic_mafic,columns=['COMPOSITION','SIO2','NA2O'])\n",
    "volcanic_felsic_mafic = volcanic_felsic_mafic.dropna()\n",
    "volcanic_felsic_mafic.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "felsic_NA20_mean = np.mean(volcanic_felsic_mafic[volcanic_felsic_mafic['COMPOSITION']=='FELSIC']['NA2O'])\n",
    "mafic_NA20_mean = np.mean(volcanic_felsic_mafic[volcanic_felsic_mafic['COMPOSITION']=='MAFIC']['NA2O'])\n",
    "\n",
    "felsic_NA20_mean - mafic_NA20_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function that can make this calculation and make a function for median difference too while we are at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_of_means(dataframe,value,category_column,category_values):\n",
    "    '''\n",
    "    Function to calculate the difference of mean from a dataframe.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe : the pandas dataframe containing the data\n",
    "    value : the column for which the mean will be calculated (a string)\n",
    "    category_column : the column that will be used to categorize the data (a string)\n",
    "    category_values : the values of the category (a list of strings)\n",
    "    '''\n",
    "    mean_1 = np.mean(dataframe[dataframe[category_column]==category_values[0]][value])\n",
    "    mean_2 = np.mean(dataframe[dataframe[category_column]==category_values[1]][value])\n",
    "    return mean_1 - mean_2\n",
    "\n",
    "def difference_of_medians(dataframe,value,category_column,category_values):\n",
    "    '''\n",
    "    Function to calculate the difference of mean from a dataframe.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe : the pandas dataframe containing the data\n",
    "    value : the column for which the mean will be calculated (a string)\n",
    "    category_column : the column that will be used to categorize the data (a string)\n",
    "    category_values : the values of the category (a list of strings)\n",
    "    '''\n",
    "    median_1 = np.median(dataframe[dataframe[category_column]==category_values[0]][value])\n",
    "    median_2 = np.median(dataframe[dataframe[category_column]==category_values[1]][value])\n",
    "    return median_1 - median_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "felsic_mafic_mean_diff = difference_of_means(volcanic_felsic_mafic,'NA2O','COMPOSITION',['FELSIC','MAFIC'])\n",
    "felsic_mafic_mean_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "felsic_mafic_median_diff = difference_of_medians(volcanic_felsic_mafic,'NA2O','COMPOSITION',['FELSIC','MAFIC'])\n",
    "felsic_mafic_median_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the null hypothesis through random permutation\n",
    "\n",
    "The difference of the means suggests that the alternative hypothesis that felsic lavas have more sodium on average is true. How can we test that this is not the result of chance?\n",
    "\n",
    "> **Predicting the Statistic Under the Null Hypothesis**\n",
    "\n",
    "> To see how the statistic should vary under the null hypothesis, we have to figure out how to simulate the statistic under that hypothesis. A clever method based on random permutations does just that\n",
    "\n",
    "If there were no difference between the two distributions in the underlying population, then whether the sodium content is from a mafic or a felsic rock should make no difference to the average. The idea, then, is to shuffle all the labels randomly among the rock samples. This is called random permutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volcanic_felsic_mafic['COMPOSITION_Shuffled'] = np.random.permutation(volcanic_felsic_mafic['COMPOSITION'].values)\n",
    "volcanic_felsic_mafic.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_of_means(volcanic_felsic_mafic,'NA2O','COMPOSITION_Shuffled',['FELSIC','MAFIC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above difference is the result of one random permutation. We want to do many random permutations to test the hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif_permuations_fel_maf_mean = []\n",
    "dif_permuations_fel_maf_median = []\n",
    "\n",
    "repetitions = 1000\n",
    "\n",
    "for i in np.arange(repetitions):\n",
    "    volcanic_felsic_mafic['COMPOSITION_Shuffled'] = np.random.permutation(volcanic_felsic_mafic['COMPOSITION'].values)\n",
    "    \n",
    "    new_mean_diff = difference_of_means(volcanic_felsic_mafic,'NA2O','COMPOSITION_Shuffled',['FELSIC','MAFIC'])\n",
    "    dif_permuations_fel_maf_mean.append(new_mean_diff) \n",
    "    \n",
    "    new_median_diff = difference_of_medians(volcanic_felsic_mafic,'NA2O','COMPOSITION_Shuffled',['FELSIC','MAFIC'])\n",
    "    dif_permuations_fel_maf_median.append(new_median_diff) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(dif_permuations_fel_maf_mean,label='permutations')\n",
    "plt.xlabel('Na$_2$O mean difference')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(dif_permuations_fel_maf_median,label='permutations')\n",
    "plt.xlabel('Na$_2$O median difference')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the distributions are centered around 0. This makes sense, because under the null hypothesis the two groups should have roughly the same average. Therefore the difference between the group averages should be around 0.\n",
    "\n",
    "## Comparing the random permutations to the actual difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(dif_permuations_fel_maf_mean,label='permutations')\n",
    "plt.scatter(felsic_mafic_mean_diff,0,color='red',zorder=1000,label='actual felsic-mafic')\n",
    "plt.xlabel('Na$_2$O mean difference')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(dif_permuations_fel_maf_median,label='permutations')\n",
    "plt.scatter(felsic_mafic_median_diff,0,color='red',zorder=1000,label='actual felsic-mafic')\n",
    "plt.xlabel('Na$_2$O median difference')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_empirical_p = np.count_nonzero(dif_permuations_fel_maf_mean >= felsic_mafic_mean_diff) / repetitions\n",
    "mean_empirical_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_empirical_p = np.count_nonzero(dif_permuations_fel_maf_median >= felsic_mafic_median_diff) / repetitions\n",
    "median_empirical_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The empirical P-values are 0, meaning that none of the 5,000 permuted samples resulted in a difference that was as large as that which is observed in the actual samples. This is only an approximation. The exact chance of getting a difference in that range is not 0, but it is vanishingly small.\n",
    "\n",
    "So it appears to be well-supported that felsic magmas have more Na$_2$O than mafic magmas.\n",
    "\n",
    "## Testing the null hypothesis that there is no difference in the sodium content of **intermediate and felsic** lavas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volcanic_felsic_int = volcanic_data[(volcanic_data['COMPOSITION']=='FELSIC') | (volcanic_data['COMPOSITION']=='INTERMEDIATE')]\n",
    "volcanic_felsic_int = volcanic_felsic_int[(volcanic_felsic_int['SIO2'] < 64) & (volcanic_felsic_int['SIO2'] > 51)]\n",
    "volcanic_felsic_int = pd.DataFrame(volcanic_felsic_int,columns=['COMPOSITION','SIO2','NA2O'])\n",
    "volcanic_felsic_int = volcanic_felsic_int.dropna()\n",
    "volcanic_felsic_int.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code for you to write**\n",
    "\n",
    "**Calculate the difference in the median and the difference in the mean between the NA2O of intermediate and felsic lavas. Assign them to variables and print them.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "felsic_int_mean_diff = #complete the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "felsic_int_median_diff = #complete the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code for you to write**\n",
    "\n",
    "**Shuffle the compositions within the `volcanic_felsic_int` dataframe. Do it 1000 times and make histogrames of the mean and median of these permutations that includes the actual median and mean that you calculated**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif_permuations_fel_int_mean = []\n",
    "dif_permuations_fel_int_median = []\n",
    "\n",
    "repetitions = 1000\n",
    "\n",
    "for i in np.arange(repetitions):\n",
    "    #complete the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "#complete the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate the p-value for the median and mean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empirical_p_mean = np.count_nonzero(dif_permuations_fel_int_mean >= felsic_int_mean_diff) / repetitions\n",
    "empirical_p_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empirical_p_median = np.count_nonzero(dif_permuations_fel_int_median >= felsic_int_median_diff) / repetitions\n",
    "empirical_p_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you reject the null hypothesis?\n",
    "\n",
    "_Write your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn in the Notebook\n",
    "\n",
    "**Export as HTML and upload to bCourses.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
